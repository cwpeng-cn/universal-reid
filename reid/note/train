from reid.data import datasets
from reid.data import transforms
from resnet import ResNet
from reid.utils import feature_operate as FO
from reid.utils.model_save_restore import *
import torch.nn as nn
import numpy as np
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader
from reid.evaluation import market_evaluate
import torch
from torch.nn import CrossEntropyLoss

from tensorboardX import SummaryWriter

writer = SummaryWriter('log')

EPOCH = 65
LR = 0.1
BATCH_SIZE = 128

train_image_path = "../ReidDatasets/Market-1501-v15.09.15/bounding_box_train"
query_path = "../ReidDatasets/Market-1501-v15.09.15/query"
gallery_path = "../ReidDatasets/Market-1501-v15.09.15/bounding_box_test"

save_path = './storage_1024'

train_transform = transforms.Compose([
    transforms.RandomSizedRectCrop(256, 128),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
train_dataset = datasets.MarketDataset(image_path=train_image_path, transform=train_transform, use_onehot=False)
train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=8, shuffle=True)

test_transform = transforms.Compose([
    transforms.Resize((256, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
query_dataset = datasets.MarketDataset(image_path=query_path, transform=test_transform, use_onehot=False)
gallery_dataset = datasets.MarketDataset(image_path=gallery_path, transform=test_transform, use_onehot=False)
query_loader = DataLoader(query_dataset, batch_size=16, shuffle=False, num_workers=4)
gallery_loader = DataLoader(gallery_dataset, batch_size=16, shuffle=False, num_workers=4)

net = ResNet(depth=50, num_features=1024, dropout=0.5, num_classes=751)
net = nn.DataParallel(net).cuda()

loss = CrossEntropyLoss()

ignored_params = list(map(id, net.module.embed_layer.parameters())) + list(map(id, net.module.last_fc.parameters()))
base_params = filter(lambda p: id(p) not in ignored_params, net.parameters())
optimizer = optim.SGD([
    {'params': base_params, 'lr_mult': LR},
    {'params': net.module.embed_layer.parameters(), 'lr_mult': LR * 10},
    {'params': net.module.last_fc.parameters(), 'lr_mult': LR * 10}
], lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)


# Schedule learning rate
def adjust_lr(epoch):
    step_size = 40
    lr = LR * (0.1 ** (epoch // step_size))
    for g in optimizer.param_groups:
        g['lr'] = lr * g.get('lr_mult', 1)


step = 0
best_map = -1
best_map_epoch = 0
best_rank1 = -1
best_rank1_epoch = 0
print("开始训练>>>")
for epoch in range(EPOCH):
    adjust_lr(epoch)
    for images, ids, cams in train_loader:
        predict = net(images.cuda())
        # loss_value = loss(predict, ids.cuda())
        predict_detach = predict.detach()
        predict_detach.requires_grad = True
        loss_value = loss(predict_detach, ids.cuda())
        optimizer.zero_grad()
        loss_value.backward()
        predict.backward(predict_detach.grad)
        optimizer.step()
        if step % 10 == 0:
            writer.add_scalar("loss", loss_value.data[0], step)
            print(step, loss_value.data[0])
        step += 1
    print("已经迭代了第{}轮".format(epoch + 1))
    if epoch + 1 > 40 and (epoch + 1) % 5 == 0:
        save_network(save_path, net, epoch)
        print("第{}轮效果评估开始>>>".format(epoch + 1))
        query_feature = FO.extract_cnn_feature(net, loader=query_loader, vis=False)
        gallery_feature = FO.extract_cnn_feature(net, loader=gallery_loader, vis=False)
        query_id, query_camera = query_loader.dataset.original_id, query_loader.dataset.cameras
        gallery_id, gallery_camera = gallery_loader.dataset.original_id, gallery_loader.dataset.cameras
        map, cmc = market_evaluate.evaluate(query_feature, np.array(query_id), np.array(query_camera), gallery_feature,
                                            np.array(gallery_id), np.array(gallery_camera), vis=False)
        print("第{}轮训练结果: map:{},rank-1:{}".format(epoch + 1, map, cmc[0]))
        if map > best_map or cmc[0] > best_rank1:
            save_network(save_path, net, epoch)
        if map > best_map:
            best_map = map
            best_map_epoch = epoch
        if cmc[0] > best_rank1:
            best_rank1 = cmc[0]
            best_cmc_epoch = epoch
print("最佳map:{},最佳rank-1{},最佳map训练轮数:{},最佳cmc训练轮数:{}".format(best_map, best_rank1, best_map_epoch, best_rank1_epoch))

